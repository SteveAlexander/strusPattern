<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<link rel="icon" type="image/ico" href="images/strus.ico" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Strus stream, a library for fast document stream processing for Strus." />
	<meta name="keywords" content="high performance document stream processing pattern matching C++" />
	<meta name="author" content="Patrick Frey &lt;patrickpfrey (a) yahoo (dt) com&gt;" />
	<link rel="stylesheet" type="text/css" href="text-profile.css" title="Text Profile" media="all" />
	<title>Strus Stream</title>
</head>

<body>
<div id="wrap">
<div id="content">
	<h1>Strus Stream</h1>
	<h2>Description</h2>
	<p id="description"><i>StrusStream</i> is an event or dataflow driven pattern detection library for 
	text processing with a competitive performance, suitable for processing large sets of patterns.
	It can be used for detecting multipart entities or structures in text. In a bigger context it can
	support NLP and entity recognition.<br/>
	Patterns are describable as expression trees with basic tokens as 
	leafs, that are recognized with regular expressions on text.</br></br>
	The name <i>StrusStream</i> reflects its event or data flow driven processing of text.
	Its programming paradigms borrow from concepts of <a href=https://en.wikipedia.org/wiki/Stream_processing">
	stream processing</a>. But it is not related to modern stream processing frameworks for event
	driven processing.
	</p>

	<h2>The Intel hyperscan library</h3>
	<p id="description"><i>StrusStream</i> uses the <a href="https://01.org/hyperscan">hyperscan</a> library from <i>Intel</i>
	for tokenization.<br/>
	Thanks to <i>Intel</i> for publishing this great work as open source.
	</p>

	<h2>Links to alternative solutions</h2>
	<p id="description">
	The following links show alternatives for pattern detection in documents.
	<ol>
	<li><a href="http://stanfordnlp.github.io/CoreNLP">CoreNLP</a>, a tool suite for different aspects of NLP,
		including <a href="http://nlp.stanford.edu/software/tokensregex.html">pattern matching</a> on text,
		licensed under <a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GPLv3</a>. 
		API available for Java. Stanford <i>CoreNLP</i> covers much more than simple pattern
		matching. It provides a workbench for all aspects of natural language processing accompanied
		by a huge knowledge base on the topic. (See for example the <a href="https://class.coursera.org/nlp/lecture">Standford video lectures</a>).
	</li>
	<li>The <a href="https://uima.apache.org/ruta.html">Uima Ruta</a> workbench for rule-based text annotation,
	licensed under the <a href="http://www.apache.org/licenses">Apache license</a>.
	APIs available for Java an C++. With Uima Ruta you get a framework to define arbitrary rules on text with
	its connectors to the big <i>Apache</i> universe for scalable data processing.
	</li>
	</ol>
	</p>

	<h2>How StrusStream works</h2>
	<p id="description">
	<i>StrusStream</i> is completely dataflow driven. It does not detect patterns by an imperative procedure 
	triggered by events in the source data stream. Though it does start the initiation of a pattern
	detection with a key event triggering it.
	But rather than subsequently executing a program, it installs for every pattern node triggered a small set
	of triggers and a slot with an expiration time. Signals are fired to the slot when an event matching
	a trigger occurrs in the subsequent event stream. The completion all awaited signals of a slot leads
	to an emission of a signal for other slots waiting for it and/or the production of a result.
	</p>

	<h3>Operators</h3>
	<p id="description">
	<i>StrusStream</i> defines patterns as expression trees of nodes. Each node represents a basic token
	in the source or operators on tuples of nodes. Most of the operators supported are named according to the
	<a href="http://www.project-strus.net/builtin_functions.htm">posting join operators</a> in the
	strus query evaluation. Not all of them are implemented though and some exist in <i>StrusStream</i>,
	but not in this form in the query evaluation:
	<h4>Token pattern matching operators</h4>
	<ol>
	<li><b>any</b>: Matches if any of the argument subexpressions or tokens matches.</li>
	<li><b>sequence</b>: Matches if the argument subexpressions or tokens appear in the order as the arguments within a proximity range of ordinal positions specified.</li>
	<li><b>sequence_struct</b>: Matches if the argument subexpressions or tokens appear in the order as the arguments within a proximity range of ordinal positions specified without a structure delimiter (e.g. end of sentence token), specified as first argument, within the span of a match.</li>
	<li><b>within</b>: Matches if the argument subexpressions or tokens appear in arbitrary order within a proximity range of ordinal positions specified.</li>
	<li><b>within_struct</b>: Matches if the argument subexpressions or tokens appear in arbitrary order within a proximity range of ordinal positions specified without a structure delimiter (e.g. end of sentence token), specified as first argument, within the span of a match.</li>
	</ol>
	</p>

	<h2>Example</h2>
	<p id="description">The following example illustrates how <i>StrusStream</i> works.
	</p>
	<h3>Example patterns defined</h3>
	<h4>Define the patterns with in a configuration file</h4>
	<p id="description">We define the example rules defined in the following listing.
	The declarations with an identifier followed by a ':' specify the tokens defined by regular expressions. The counting of the different token start positions defines the ordinal positions of the tokens. The number following a '^' after the name of the token defines its level, a sort of priorization. Tokens covered completely by a token of a higher level are not part of the output and for ordinal position assignments. We use the possibiliy to superseed rules in our example to define a hierarchy <b>SENT</b> (end of sentence) &lt; <b>ABBREV</b> (abbreviation) &lt; <b>URL</b> &lt; <b>EMAIL</b>. It means that a dot is an end of sentence marker if not part of an abbreviation, URL or email address. An abbreviation is not recognized as such, if part of an URL. An URL is not an URL, if part of an email address, etc.
	<br/>The declarations with an identifier followed by a '=' specify the patterns defined on tokens with the ordinal position as position reference for proximity range specifications.
	</p>
	<pre>
WORD ^1		:/\b\w+\b/;
SENT ^2		:/[.]/;
ABBREV ^3	: /\b[aA]bbr[\.]/ | /\b[aA]d[cjv][\.]/ | /\b[oO]bj[\.]/ | /\b[pP]seud[\.]/
		|  /\b[tT]rans[\.]/ | /\b[A-Za-z][\.][a-z][\.]/ | /\betc[\.]/ | /\bca[\.]/
		| /\b[mM]rs[\.]/ | /\b[pP]rof[\.]/ | /\b[rR]ev[\.]/ | /\b[hH]on[\.]/ | /\b[hH]rs[\.]/
		| /\b[A-Za-z][btlsr][\.]/ | /\b[gG]en[\.]/ | /\b[sS]ing[\.]/ | /\b[sS]yn[\.]/
		| /\b[aA]ve[\.]/ | /\b[d]dD]ept[\.]/ | /\b[eE]st[\.]/ | /\b[fF]ig[\.]/ | /\b[iI]nc[\.]/
		| /\b[oO]z[\.]/ | /\b[nN]o[\.]/ | /\b[sS]q[\.]/ | /\b[aA]ssn[\.]/ | /\b[tT]rans[\.]/;
ABBREV ^4	: /\bet\sal[\.]/ | /\b[rR][\.][iI][\.][pP]\b/;
URL ^5		: @([^\s/?\.#-][^\s/?\.#-]+\.)(aero|asia|biz|cat|com|coop|edu|gov|info|int|jobs|mil|mobi|museum|name|net|org|pro|tel|travel|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cu|cv|cx|cy|cz|cz|de|dj|dk|dm|do|dz|ec|ee|eg|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mn|mn|mo|mp|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|nom|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ra|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|sj|sk|sl|sm|sn|so|sr|st|su|sv|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|xyz|ye|yt|yu|za|zm|zw|arpa)@;
URL ^6		: @\b(https?://|ftp://)?([^\s/?\.#-]+\.)([^\s/?\.#-]+\.)([a-z]{2,6})(/[^\s]*)?@;
EMAIL ^7	: /\b([a-z0-9_\.-]+)@([\da-z\.-]+)\.([a-z\.]{2,6})\b/;
CAPWORD ^1	: /\b\p{Lu}\p{Ll}+\b/;

Name		= sequence( firstname=[0.75]CAPWORD, surname=CAPWORD | 2 );
Contact		= sequence_struct( SENT, Name, email=EMAIL | 10 );
	</pre>
	<p id="description">
	A "Name" is defined as a sequence of two words with capitalized first letter in a proximity distance of 2 (ordinal position distance, number of tokens)
	In this example the variable assignment of firstname gets the weight 0.75 assigned. Weigths are not
	interpreted or used by <i>StrusStream</i>. They are there for the user if part or the interpretation of the result.
	<br/>
	A "Contact" is defined as sequence of a name as we defined it and an email address in in a proximity
	distance of maximum 10 tokens, without an end of sentence marker appearing in between a candidate match.
	</p>
	<h4>Define the patterns in C++</h4>
	<p id="description"> ... </p>
	<h4>Define the patterns in Python</h4>
	<p id="description"> ... </p>

	<h3>Example input</h3>
	<pre>
This is an example document about Prof. John Doe, contact mail@etc.com, or visit www.etc.ch.
He is responsible for development, etc..
	</pre>
	<h3>Tokenization</h3>
	<p id="description">The following output shows the tokens recognized with our set of patterns defined:
	</p>
	<pre>
token WORD(1) at 1[0:4] 'This'
token CAPWORD(6) at 1[0:4] 'This'
token WORD(1) at 2[5:2] 'is'
token WORD(1) at 3[8:2] 'an'
token WORD(1) at 4[11:7] 'example'
token WORD(1) at 5[19:8] 'document'
token WORD(1) at 6[28:5] 'about'
token ABBREV(3) at 7[34:5] 'Prof.'
token WORD(1) at 8[40:4] 'John'
token CAPWORD(6) at 8[40:4] 'John'
token WORD(1) at 9[45:3] 'Doe'
token CAPWORD(6) at 9[45:3] 'Doe'
token WORD(1) at 10[50:7] 'contact'
token EMAIL(5) at 11[58:12] 'mail@etc.com'
token WORD(1) at 12[72:2] 'or'
token WORD(1) at 13[75:5] 'visit'
token URL(4) at 14[81:10] 'www.etc.ch'
token SENT(2) at 15[91:1] '.'
token WORD(1) at 16[93:2] 'He'
token CAPWORD(6) at 16[93:2] 'He'
token WORD(1) at 17[96:2] 'is'
token WORD(1) at 18[99:11] 'responsible'
token WORD(1) at 19[111:3] 'for'
token WORD(1) at 20[115:11] 'development'
token ABBREV(3) at 21[128:4] 'etc.'
token SENT(2) at 22[132:1] '.'
	</pre>

	<h3>Rule matching</h3>
	<p id="description">The following output of the program <i>strusPatternMatch</i> shows the entities recognized with our example patterns:
	</p>
	<pre>
result Name at 8:
        item surname at 9 [45:3] 1 'Doe'
        item firstname at 8 [40:4] 0.75 'John'

result Contact at 8:
        item email at 11 [58:12] 1 'mail@etc.com'
        item firstname at 8 [40:4] 0.75 'John'
        item surname at 9 [45:3] 1 'Doe'
	</pre>

	<h2>Performance measurements on an Intel NUC (NUC6i3SYK)</h2>
	<p id="description">The following runs show the behaviour of the <i>StrusStream</i> pattern matching without tokenization. We just use random documents represented as <a href="http://mathworld.wolfram.com/ZipfDistribution.html">Zipf distributed</a> random numbers, assuming 30'000 different terms in the whole collection. Each document contains 1000 such terms.
	The patterns are sequences of two random terms (<i>Zipf distribution</i> applied here too) within a proximity range of 1 to 10 with smaller proximity being much more likely than larger proximity conditions.
	We start 4 threads with the same pattern set with different input documents and test with 10 to 10'000'000 patterns evaluated.
	<br/><br/>
	This test does not help to estimate the performance of the system solving a real world problems. But it can help to estimate its behaviour when confronted with real world problems, if you look at the numbers in detail, like how many patterns were activated or how many patterns matched, etc.. Leaving the regular expression matching out in this test is not a problem since you can for sure assume, that the ultra fast <i>hyperscan</i> library from Intel will not be a bottleneck.
	For real world problems, you also have to take into account, that patterns get more complicated, with subexpressions, more complex operators than a simple sequence and variables assigned for items, you want to be part of the result. The numbers here are just representing the numbers for a set of the simplest type of pattern possible. If you measure the performance for pattern nodes detecting sequences of terms or subexpressions within the same sentence sentence, you will roughly double the execution time. Same for nodes detecting the appearance of two features in whatever order compared with a simple sequence.
	If you have more complex patterns, e.g. expression trees with many nodes, you have to count every node as unit and you have to take into account that every sub expression matched produces an event that gets part of the input processed.
	<br/><br/>
	The tests were run on an <i>Intel NUC</i> (<a href="http://www.intel.com/content/www/us/en/nuc/nuc-kit-nuc6i3syk.html">NUC6i3SYK</a>), a system with <b>4 GB RAM</b> is enough for processing the test with <b>10'000'000</b> nodes.
	<br/><br/>
	</p>
	<pre>
for dd in 10 100 1000 10000 100000 1000000 10000000; do
src/testRandomPatternMatch -t 4 -o 30000 25 1000 $dd sequence; done

starting 4 threads for rule evaluation ...
OK
processed 10 patterns on 100 documents with total 0 matches in 185 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 0
	nofProgramsInstalled: 491
	nofTriggersAvgActive: 0
	nofSignalsFired: 491

starting 4 threads for rule evaluation ...
OK
processed 100 patterns on 100 documents with total 17 matches in 188 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 0
	nofProgramsInstalled: 33967
	nofTriggersAvgActive: 1
	nofSignalsFired: 33984

starting 4 threads for rule evaluation ...
OK
processed 1000 patterns on 100 documents with total 6153 matches in 198 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 2035
	nofProgramsInstalled: 169880
	nofTriggersAvgActive: 6
	nofSignalsFired: 174716

starting 4 threads for rule evaluation ...
OK
processed 10000 patterns on 100 documents with total 55236 matches in 306 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 30437
	nofProgramsInstalled: 1987366
	nofTriggersAvgActive: 84
	nofSignalsFired: 2023920

starting 4 threads for rule evaluation ...
OK
processed 100000 patterns on 100 documents with total 655431 matches in 2418 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 360835
	nofProgramsInstalled: 20092579
	nofTriggersAvgActive: 848
	nofSignalsFired: 20545764

starting 4 threads for rule evaluation ...
OK
processed 1000000 patterns on 100 documents with total 6277057 matches in 55087 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 4194327
	nofProgramsInstalled: 198949620
	nofTriggersAvgActive: 8465
	nofSignalsFired: 202923433

starting 4 threads for rule evaluation ...
OK
processed 10000000 patterns on 100 documents with total 61650742 matches in 844535 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 42381393
	nofProgramsInstalled: 1990633664
	nofTriggersAvgActive: 84649
	nofSignalsFired: 2028410811
	</pre>

<h4>Interpretation</h4>
<p id="description">
<ol>
<li>processed <b>N</b> patterns on 100 documents with total <b>X</b> matches in <b>T</b> milliseconds:
<ul>
<li><b>N</b>: Number of patterns, sequences of two tokens in a ordinal position distance of 1 to 10 (possibly with unspecified tokens appearing in between) defined</li>
<li><b>X</b>: Total number of matching token sequences in 100 documents</li>
<li><b>T</b>: Execution time for processing all 100 documents</li>
</ul>
<li><b>nofAltKeyProgramsInstalled</b>: Tells how many optimized patterns with an alternative key event were triggered for execution by a key event during the whole processing of the 100 documents. A pattern is optimized, if an initial token, triggering the evaluation of the pattern, is statistically appearing too often. In this case a valable alternative token, if it exists, is chosen, and the initial token event is replayed for the pattern to match. The intention of this optimization is to reduce the number or hits and the following processing of rules that may not match. As example consider a rule like "The world", that is triggered with every appearance of "the". Triggering the rule with "world" is better in english text.</li>
<li><b>nofProgramsInstalled</b>: Tells how many patterns were triggered for execution by a key event during the whole processing of the 100 documents.</li>
<li><b>nofTriggersAvgActive</b>: Tells how many patterns were active (waiting for events to complete the pattern match) in average for every input token processed.</li>
<li><b>nofSignalsFired</b>: Tells how many signals were fired during the whole processing of the 100 documents. An active pattern listens for signals fired on a slot. The pattern matches on a completion condition on the slot.</li>
</ol>
</p>
</div>
</div>
<h4>Performance measurement plot</h4>
<p id="description">The following plot shows the measured execution time against the number of sequence 
rule nodes evaluated.
</p>
<img src="perfplot.png" width="500" alt="performance plot" />

<h2>Open problems and bugs</h2>
<h4>within and within_struct greediness</h4>
<p id="description">
Patterns with the operator <b>within</b> or <b>within_struct</b> currently do not work correctly, if
accepted sets of subexpressions are not disjunct. This is due to the greediness of the algorithm,
that does not follow alternative paths or backtrack. To illustrate the problem, have a look at the
pattern matching the elements "(A B)" and "A" in any order and the source "ABA". The current situation
is that the pattern matcher recognizes "A" as "A" and does not accept a signal for "AB" anymore at the
same position for this pattern.
<br/>
There are straightforward solutions to this problem, but I did not find yet a good one.
I am aware of that problem and I know that it cannot be neglected.
Currently you have to formulate your 'within' rules as all possible permutations of sequences
(2 patterns "((A B) A)" and "(A (A B))", if you have 'within' rules with non disjunct accepted sets.
Sequences do not have this problem.
</p>

<h2>Testing</h2>
<p id="description">We tested the token pattern matching of <i>StrusStream</i> with random generated
rules on random generated documents verified with an alternative implementation. Currently the
tests fail because of differences due to the problems with operators on subexpressions with 
non disjuct sets of accepted input. We are working on the problem.
</p>

<h2>Caveats</h2>
<p id="description"><i>StrusStream</i> handles events immediately when they are seen.
This can lead to anomalies, when formulating restrictions, e.g. with 'sequence_struct' or 'within_struct'
in cases the structure delimiter gets the same ordinal position assigned than another token that is part of the
pattern. When the last element of a rule is detected without passing over a structure element, that is part of 
the restriction condition, then the result is emitted, even if a restriction event with the same ordinal position,
that should overrule the decision, happens thereafter. Another anomaly of this kind can happen, when the 
restricting element of a rule occurrs with the same position, but before the key event triggering the pattern.
<br/>
Practically I do not see too bad consequences of this behaviour, because structure delimiters usually get their
own ordinal position assigned. But it might be needed in the future to treat these cases differently.
<br/>
At the moment I just premention the expected behaviour.
</p>

<h2>Resume</h2>
<p id="description"><i>StrusStream</i> provides token pattern matching in a competitive performance for
large sets of rules sutable for <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">NER</a>,
<a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> and other structured entity 
detection on text.
The implementation is maybe not optimal in numbers of reads and writes of memory and in 
numbers of branching instructions, but it is software with a good flow. It has
simple operations mainly operating on local (near, on chip) memory, able to use SIMD capabilities
of modern CPUs and it accesses new (far away) memory mainly for feeding the system.
<br/>
For users that do not need arbitrary programs to define patterns and for users, that can live with 
the restrictions of the model of <i>StrusStream</i>, the prospect of the performance may be convincing.
</p>
</body>
</html>

