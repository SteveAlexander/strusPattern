<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<link rel="icon" type="image/ico" href="images/strus.ico" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Strus stream, a library for high performance document stream processing for Strus." />
	<meta name="keywords" content="high performance document stream processing pattern matching C++" />
	<meta name="author" content="Patrick Frey &lt;patrickpfrey (a) yahoo (dt) com&gt;" />
	<link rel="stylesheet" type="text/css" href="text-profile.css" title="Text Profile" media="all" />
	<title>Strus Stream</title>
</head>

<body>
<div id="wrap">
<div id="content">
	<h1>Strus Stream</h1>
	<h2>Description</h2>
	<p id="description"><i>StrusStream</i> is a high performance pattern detection library, suitable for processing large sets of rules.
	It can be used for detecting multipart entities in text. In a bigger context it can support NLP and entity recognition,
	wheter you use the large set of patterns to detect entities directly or as hint for a system learning entities.
	The patterns that can be recognized are describable as expression trees with basic tokens as leafs, that are recognized with 
	regular expressions on text.</br>
	Some of the expression tree node operators supported are named according to the
	<a href="http://www.project-strus.net/builtin_functions.htm">posting join operators</a> in the
	strus query evaluation. Not all of them are implemented though and some exist in the token 
	pattern matching, but not in this form in the query evaluation:
	<h4>Token pattern matching operators</h4>
	<ol>
	<li><b>any</b>: Matches is any of the argument subexpressions or tokens matches.</li>
	<li><b>sequence</b>: Matches if the argument subexpressions or tokens appear in the order as the arguments withing a proximity range specified.</li>
	<li><b>sequence_struct</b>: Matches if the argument subexpressions or tokens appear in the order as the arguments withing a proximity range specified without a structure delimiter (e.g. end of sentence token) specified as first argument in between.</li>
	<li><b>within</b>: Matches if the argument subexpressions or tokens appear withing a proximity range specified. The argument expression spans may overlap, whereas in the case of <i>sequence</i> or <i>sequence_struct</i> they must not.</li>
	<li><b>within_struct</b>: Matches if the argument subexpressions or tokens appear withing a proximity range specified without a structure delimiter (e.g. end of sentence token) specified as first argument in between.</li>
	</ol>
	</p>

	<h2>The Intel hyperscan library</h3>
	<p id="description">For tokenization, <i>StrusStream</i> uses the <a href="https://01.org/hyperscan">hyperscan</a> library from <i>Intel</i>.
	</p>

	<h2>Links about the topic and alternative solutions</h2>
	<p id="description">
	<ol>
	<li><a href="https://class.coursera.org/nlp/lecture">Video lectures</a> from the Stanford Natural Language Processing group
	about several aspects of NLP and information retrieval.
	</li>
	<li><a href="http://stanfordnlp.github.io/CoreNLP">CoreNLP</a>, a tool suite for different aspects of NLP,
		namely for <a href="http://nlp.stanford.edu/software/tokensregex.html">pattern matching</a>,
		licensed under <a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GPLv3</a>. 
		API available for Java.
	</li>
	<li>The <a href="https://uima.apache.org/ruta.html">Uima Ruta</a> workbench for rule-based text annotation,
	licensed under the <a href="http://www.apache.org/licenses">Apache license</a>.
	APIs available for Java an C++.
	</li>
	</ol>
	</p>

	<h2>Example</h2>
	<p id="description">The following example illustrates how <i>StrusStream</i> works.
	</p>
	<h3>Example patterns defined</h3>
	<h4>Define the patterns with in a configuration file</h4>
	<p id="description">We define the example rules defined in the following listing.
	The declarations with an identifier followed by a ':' specify the tokens defined by regular expressions. The counting ot the different token start positions defines the ordinal positions of the tokens. The number following a '^' after the name of the token defines its level, a sort of priorization (tokens covered completely by a token of a higher level are not part of the output and for ordinal position assignments).
	The declarations with an identifier followed by a '=' specify the patterns defined on tokens with the ordinal position as position reference for proximity range specifications.
	</p>
	<pre>
WORD ^1		:/\b\w+\b/;
SENT ^2		:/[.]/;
ABBREV ^3	: /\b[aA]bbr[\.]/ | /\b[aA]d[cjv][\.]/ | /\b[oO]bj[\.]/ | /\b[pP]seud[\.]/
		|  /\b[tT]rans[\.]/ | /\b[A-Za-z][\.][a-z][\.]/ | /\betc[\.]/ | /\bca[\.]/
		| /\b[mM]rs[\.]/ | /\b[pP]rof[\.]/ | /\b[rR]ev[\.]/ | /\b[hH]on[\.]/ | /\b[hH]rs[\.]/
		| /\b[A-Za-z][btlsr][\.]/ | /\b[gG]en[\.]/ | /\b[sS]ing[\.]/ | /\b[sS]yn[\.]/
		| /\b[aA]ve[\.]/ | /\b[d]dD]ept[\.]/ | /\b[eE]st[\.]/ | /\b[fF]ig[\.]/ | /\b[iI]nc[\.]/
		| /\b[oO]z[\.]/ | /\b[nN]o[\.]/ | /\b[sS]q[\.]/ | /\b[aA]ssn[\.]/ | /\b[tT]rans[\.]/;
ABBREV ^4	: /\bet\sal[\.]/ | /\b[rR][\.][iI][\.][pP]\b/;
URL ^5		: @([^\s/?\.#-][^\s/?\.#-]+\.)(aero|asia|biz|cat|com|coop|edu|gov|info|int|jobs|mil|mobi|museum|name|net|org|pro|tel|travel|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cu|cv|cx|cy|cz|cz|de|dj|dk|dm|do|dz|ec|ee|eg|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mn|mn|mo|mp|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|nom|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ra|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|sj|sk|sl|sm|sn|so|sr|st|su|sv|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|xyz|ye|yt|yu|za|zm|zw|arpa)@;
URL ^6		: @\b(https?://|ftp://)?([^\s/?\.#-]+\.)([^\s/?\.#-]+\.)([a-z]{2,6})(/[^\s]*)?@;
EMAIL ^7	: /\b([a-z0-9_\.-]+)@([\da-z\.-]+)\.([a-z\.]{2,6})\b/;
CAPWORD ^1	: /\b\p{Lu}\p{Ll}+\b/;

Name		= sequence( firstname=[0.75]CAPWORD, surname=CAPWORD | 2 );
Contact		= sequence_struct( SENT, Name, email=EMAIL | 10 );
	</pre>
	<h4>Define the patterns in C++</h4>
	<p id="description"> ... </p>
	<h4>Define the patterns in Python</h4>
	<p id="description"> ... </p>

	<h3>Example input</h3>
	<pre>
This is an example document about Prof. John Doe, contact mail@etc.com, or visit www.etc.ch.
He is responsible for development, etc..
	</pre>
	<h3>Tokenization</h3>
	<p id="description">The following output shows the tokens recognized with our set of rules defined:
	</p>
	<pre>
token WORD(1) at 1[0:4] 'This'
token CAPWORD(6) at 1[0:4] 'This'
token WORD(1) at 2[5:2] 'is'
token WORD(1) at 3[8:2] 'an'
token WORD(1) at 4[11:7] 'example'
token WORD(1) at 5[19:8] 'document'
token WORD(1) at 6[28:5] 'about'
token ABBREV(3) at 7[34:5] 'Prof.'
token WORD(1) at 8[40:4] 'John'
token CAPWORD(6) at 8[40:4] 'John'
token WORD(1) at 9[45:3] 'Doe'
token CAPWORD(6) at 9[45:3] 'Doe'
token WORD(1) at 10[50:7] 'contact'
token EMAIL(5) at 11[58:12] 'mail@etc.com'
token WORD(1) at 12[72:2] 'or'
token WORD(1) at 13[75:5] 'visit'
token URL(4) at 14[81:10] 'www.etc.ch'
token DOT(2) at 15[91:1] '.'
token WORD(1) at 16[93:2] 'He'
token CAPWORD(6) at 16[93:2] 'He'
token WORD(1) at 17[96:2] 'is'
token WORD(1) at 18[99:11] 'responsible'
token WORD(1) at 19[111:3] 'for'
token WORD(1) at 20[115:11] 'development'
token ABBREV(3) at 21[128:4] 'etc.'
token DOT(2) at 22[132:1] '.'
	</pre>

	<h3>Rule matching</h3>
	<p id="description">The following output of the program <i>strusPatternMatch</i> shows the entities recognized with our set of rules (patterns of tokens) defined:
	</p>
	<pre>
result Name at 8:
        item surname at 9 [45:3] 1 'Doe'
        item firstname at 8 [40:4] 0.75 'John'

result Contact at 8:
        item email at 11 [58:12] 1 'mail@etc.com'
        item firstname at 8 [40:4] 0.75 'John'
        item surname at 9 [45:3] 1 'Doe'
	</pre>

	<h2>Performance measurements on an Intel NUC (NUC6i3SYK)</h2>
	<p id="description">The following runs show the behaviour of the <i>StrusStream</i> pattern matching without tokenization. We just use random documents represented as Zipf distributed random numbers, assuming 30'000 different terms in the whole collection. Each document contains 1000 such terms.
	The patterns are sequences of two random terms (Zipf distribution applied here too) within a proximity range of 1 to 10 with smaller proximity being much more likely than larger proximity conditions.
	We start 4 threads with the same rule set with different input documents and test with 10 to 10'000'000 patterns evaluated.
	This test does not help to estimate the performance of the system solving a real world problems. But it can help to estimate its behaviour when confronted with real world problems, if you look at the numbers in detail, like how many rules where triggered, how many rules matched, etc.. Leaving the regular expression matching out in this test is not a problem since you can assume, that the ultra fast <i>hyperscan</i> library from Intel will not be a bottleneck.
	For real world problems, you also have to take into account, that rules get more complicated, with subexpressions, more complex operators than a simple sequence and variables assigned for items, you want to be part of the result. The numbers here are just representing the numbers for a set of the simplest type of rule possible. If you measure the performance for rule nodes detecting sequences of terms or subexpressions within the same sentence sentence, you will roughly double the execution time. Same for nodes detecting the appearance of two features in whatever order compared with a simple sequence.
	If you have more complex rules, consisting of many nodes, you have to count every node as unit and you have to take into account that every sub expression matched produces an event that gets part of the input processed.
	</p>
	<pre>
for dd in 10 100 1000 10000 100000 1000000 10000000; do
src/testRandomPatternMatch -t 4 -o 30000 25 1000 $dd sequence; done

starting 4 threads for rule evaluation ...
OK
processed 10 patterns on 100 documents with total 0 matches in 185 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 0
	nofProgramsInstalled: 491
	nofTriggersAvgActive: 0
	nofTriggersFired: 491

starting 4 threads for rule evaluation ...
OK
processed 100 patterns on 100 documents with total 17 matches in 188 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 0
	nofProgramsInstalled: 33967
	nofTriggersAvgActive: 1
	nofTriggersFired: 33984

starting 4 threads for rule evaluation ...
OK
processed 1000 patterns on 100 documents with total 6153 matches in 198 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 2035
	nofProgramsInstalled: 169880
	nofTriggersAvgActive: 6
	nofTriggersFired: 174716

starting 4 threads for rule evaluation ...
OK
processed 10000 patterns on 100 documents with total 55236 matches in 306 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 30437
	nofProgramsInstalled: 1987366
	nofTriggersAvgActive: 84
	nofTriggersFired: 2023920

starting 4 threads for rule evaluation ...
OK
processed 100000 patterns on 100 documents with total 655431 matches in 2418 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 360835
	nofProgramsInstalled: 20092579
	nofTriggersAvgActive: 848
	nofTriggersFired: 20545764

starting 4 threads for rule evaluation ...
OK
processed 1000000 patterns on 100 documents with total 6277057 matches in 55087 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 4194327
	nofProgramsInstalled: 198949620
	nofTriggersAvgActive: 8465
	nofTriggersFired: 202923433

starting 4 threads for rule evaluation ...
OK
processed 10000000 patterns on 100 documents with total 61650742 matches in 844535 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 42381393
	nofProgramsInstalled: 1990633664
	nofTriggersAvgActive: 84649
	nofTriggersFired: 2028410811
	</pre>
</div>
</div>
<h4>Performance measurement plot</h4>
<p id="description">The following plot shows the measured execution time against the number of sequence 
rule nodes evaluated.
</p>
<img src="perfplot.png" width="500" alt="performance plot" />
</body>
</html>

